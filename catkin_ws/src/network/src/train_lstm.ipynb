{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision\n",
    "import torch.optim.lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "EPOCH = 50\n",
    "GAMMA = 0.9\n",
    "STEP_SIZE = 200\n",
    "LR = 0.001\n",
    "USE_GPU = True\n",
    "decoder = ['buoy', 'dock', 'light_buoy', 'totem']\n",
    "data_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path = '/media/arg_ws3/TOSHIBA EXT/data/trajectory/root.txt'\n",
    "img_path = '/media/arg_ws3/TOSHIBA EXT/data/trajectory/images/'\n",
    "ann_path = '/media/arg_ws3/TOSHIBA EXT/data/trajectory/annotations/'\n",
    "model_path = '../model/'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "data_list_file = open(list_path,'r')\n",
    "raw_data_list = data_list_file.read().splitlines()\n",
    "data_list = []\n",
    "for data in raw_data_list:\n",
    "    data_split = data.split(',')\n",
    "    first_frame = data_split[0]\n",
    "    data_len = int(data_split[1])\n",
    "    if data_len >= 10:\n",
    "        data_list.append([first_frame, data_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Layer Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRN(nn.Module):\n",
    "    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=True):\n",
    "        super(LRN, self).__init__()\n",
    "        self.ACROSS_CHANNELS = ACROSS_CHANNELS\n",
    "        if ACROSS_CHANNELS:\n",
    "            self.average=nn.AvgPool3d(kernel_size=(local_size, 1, 1),\n",
    "                    stride=1,\n",
    "                    padding=(int((local_size-1.0)/2), 0, 0))\n",
    "        else:\n",
    "            self.average=nn.AvgPool2d(kernel_size=local_size,\n",
    "                    stride=1,\n",
    "                    padding=int((local_size-1.0)/2))\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.ACROSS_CHANNELS:\n",
    "            div = x.pow(2).unsqueeze(1)\n",
    "            div = self.average(div).squeeze(1)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        else:\n",
    "            div = x.pow(2)\n",
    "            div = self.average(div)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        x = x.div(div)\n",
    "        return x\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class alexnet_conv_layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(alexnet_conv_layers, self).__init__()\n",
    "        self.base_features = torchvision.models.alexnet(pretrained = True).features\n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(64, out_channels=16, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(192, out_channels=32, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.skip5 = nn.Sequential(\n",
    "            nn.Conv2d(256, out_channels=64, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Linear(37104 * 2, 2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Freeze those weights\n",
    "        for p in self.base_features.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def forward(self, x, y):\n",
    "        layer_extractor_x = []\n",
    "        layer_extractor_y = []\n",
    "        for idx, model in enumerate(self.base_features):\n",
    "            x = model(x)\n",
    "            y = model(y)\n",
    "            if idx in {2, 5, 11}: # layer output of conv1, conv2 , conv5(before pooling layer)\n",
    "                layer_extractor_x.append(x)\n",
    "                layer_extractor_y.append(y)\n",
    "                \n",
    "        x_out_flat = x.view(1, -1) #(1, 256, 6, 6) --> (1, 9216)\n",
    "        x_out_skip1 = self.skip1(layer_extractor_x[0]) #(1, 64, 27, 27) -> (11664)\n",
    "        x_out_skip2 = self.skip2(layer_extractor_x[1]) #(1, 192, 13, 13) -> (5408)\n",
    "        x_out_skip5 = self.skip5(layer_extractor_x[2]) #(1, 256, 13, 13) -> (10816)\n",
    "        x_out = torch.cat((x_out_skip1, x_out_skip2, x_out_skip5, x_out_flat), dim=1)\n",
    "        \n",
    "        y_out_flat = y.view(1, -1) #(1, 256, 6, 6) --> (1, 9216)\n",
    "        y_out_skip1 = self.skip1(layer_extractor_y[0]) #(1, 64, 27, 27) -> (11664)\n",
    "        y_out_skip2 = self.skip2(layer_extractor_y[1]) #(1, 192, 13, 13) -> (5408)\n",
    "        y_out_skip5 = self.skip5(layer_extractor_y[2]) #(1, 256, 13, 13) -> (10816)\n",
    "        y_out = torch.cat((y_out_skip1, y_out_skip2, y_out_skip5, y_out_flat), dim=1)\n",
    "        \n",
    "        final_out = torch.cat((x_out, y_out), dim=1)\n",
    "        conv_out = self.conv6(final_out) # (1, 2048)\n",
    "        return conv_out\n",
    "def adjust_learning_rate(optimizer):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * 0.1\n",
    "        print(\"Change learning rate to: \", param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51])\n",
      "torch.Size([1, 51])\n"
     ]
    }
   ],
   "source": [
    "a = Variable(torch.rand(1, 51)).cuda()\n",
    "print(a.shape)\n",
    "b = torch.zeros(1, 51).cuda()\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PredictNet,self).__init__()\n",
    "        self.LSTM_SIZE = 256\n",
    "        alexnet = torchvision.models.alexnet(pretrained = True)\n",
    "        self.feature = alexnet.features\n",
    "        classifier = list(alexnet.classifier.children())\n",
    "        self.classifier = nn.Sequential(*classifier[:-1])\n",
    "        self.lstm1_x =nn.LSTMCell(4096 + 1, self.LSTM_SIZE)\n",
    "        self.lstm2_x = nn.LSTMCell(self.LSTM_SIZE, self.LSTM_SIZE)\n",
    "        self.lstm1_y =nn.LSTMCell(4096 + 1, self.LSTM_SIZE)\n",
    "        self.lstm2_y = nn.LSTMCell(self.LSTM_SIZE, self.LSTM_SIZE)\n",
    "        self.linear_x = nn.Linear(self.LSTM_SIZE, 1)\n",
    "        self.linear_y = nn.Linear(self.LSTM_SIZE, 1)\n",
    "        \n",
    "        self.h_x1 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.h_y1 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.h_x2 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.h_y2 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.c_x1 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.c_y1 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.c_x2 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.c_y2 = self.get_hidden(self.LSTM_SIZE)\n",
    "\n",
    "    def init_hidden(self, num):\n",
    "        self.h_x1 = self.h_x1.detach()\n",
    "        self.h_y1 = self.h_y1.detach()\n",
    "        self.h_x2 = self.h_x2.detach()\n",
    "        self.h_y2 = self.h_y2.detach()\n",
    "        self.c_x1 = self.c_x1.detach()\n",
    "        self.c_y1 = self.c_y1.detach()\n",
    "        self.c_x2 = self.c_x2.detach()\n",
    "        self.c_y2 = self.c_y2.detach()\n",
    "        \n",
    "        self.h_x1 = self.get_hidden(num)\n",
    "        self.h_y1 = self.get_hidden(num)\n",
    "        self.h_x2 = self.get_hidden(num)\n",
    "        self.h_y2 = self.get_hidden(num)\n",
    "        self.c_x1 = self.get_hidden(num)\n",
    "        self.c_y1 = self.get_hidden(num)\n",
    "        self.c_x2 = self.get_hidden(num)\n",
    "        self.c_y2 = self.get_hidden(num)\n",
    "\n",
    "    def get_hidden(self, num):\n",
    "        if USE_GPU:\n",
    "            #return (Variable(torch.rand(1, num)).cuda(), Variable(torch.rand(1, num)).cuda())\n",
    "            return Variable(torch.rand(1, num)).cuda()\n",
    "            #return torch.zeros(1, num).cuda()\n",
    "        else:\n",
    "            #return (Variable(torch.rand(1, num)), Variable(torch.rand(1, num)))\n",
    "            return Variable(torch.rand(1, num))\n",
    "            #return torch.zeros(t1, num)\n",
    "        \n",
    "    def forward(self, img, input_x, input_y):\n",
    "        '''h_x1 = torch.zeros(1, self.LSTM_SIZE).cuda()\n",
    "        h_y1 = torch.zeros(1, self.LSTM_SIZE).cuda()\n",
    "        h_x2 = torch.zeros(1, self.LSTM_SIZE).cuda()\n",
    "        h_y2 = torch.zeros(1, self.LSTM_SIZE).cuda()\n",
    "        c_x1 = torch.zeros(1, self.LSTM_SIZE).cuda()\n",
    "        c_y1 = torch.zeros(1, self.LSTM_SIZE).cuda()\n",
    "        c_x2 = torch.zeros(1, self.LSTM_SIZE).cuda()\n",
    "        c_y2 = torch.zeros(1, self.LSTM_SIZE).cuda()'''\n",
    "        \n",
    "        img_features = self.feature(img.unsqueeze(0))\n",
    "        img_features = img_features.view(img_features.size(0), -1)\n",
    "        img_features = self.classifier(img_features).view(-1)\n",
    "        x = input_x\n",
    "        y = input_y\n",
    "        \n",
    "        '''cat_x = torch.cat((img_features, x), dim=0).view(1, -1)\n",
    "        h_x1, c_x1 = self.lstm1_x(cat_x, (h_x1, c_x1))\n",
    "        h_x2, c_x2 = self.lstm2_y(h_x1, (h_x2, c_x2))\n",
    "        output_x = self.linear_x(h_x2)\n",
    "        \n",
    "        cat_y = torch.cat((img_features, y), dim=0).view(1, -1)\n",
    "        h_y1, c_y1 = self.lstm1_y(cat_y, (h_y1, c_y1))\n",
    "        h_y2, c_y2 = self.lstm2_y(h_y1, (h_y2, c_y2))\n",
    "        output_y = self.linear_y(h_y2)'''\n",
    "        \n",
    "        cat_x = torch.cat((img_features, x), dim=0).view(1, -1)\n",
    "        self.h_x1, self.c_x1 = self.lstm1_x(cat_x, (self.h_x1, self.c_x1))\n",
    "        self.h_x2, self.c_x2 = self.lstm2_y(self.h_x1, (self.h_x2, self.c_x2))\n",
    "        output_x = self.linear_x(self.h_x2)\n",
    "        \n",
    "        cat_y = torch.cat((img_features, y), dim=0).view(1, -1)\n",
    "        self.h_y1, self.c_y1 = self.lstm1_y(cat_y, (self.h_y1, self.c_y1))\n",
    "        self.h_y2, self.c_y2 = self.lstm2_y(self.h_y1, (self.h_y2, self.c_y2))\n",
    "        output_y = self.linear_y(self.h_y2)\n",
    "        output = torch.cat((output_x, output_y))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'np.random.seed(0)\\ntorch.manual_seed(0)\\nnet = PredictNet()\\n#net.double()\\ncriterion = nn.MSELoss()\\noptimizer = torch.optim.LBFGS(net.parameters(), lr=0.1)\\nif USE_GPU:\\n    net = net.cuda()\\n    criterion = criterion.cuda()\\nnet = train_model(optimizer, criterion, net, 1)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "img_transform = transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                    ])'''\n",
    "def train_model(optimizer, criterion, net, num_epochs):\n",
    "    x = None\n",
    "    y = None\n",
    "    img = None\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch != 0 and epoch % 5 == 0:\n",
    "            adjust_learning_rate(optim)\n",
    "        curr_loss = 0.0\n",
    "        dataset_size = len(data_list)\n",
    "        sample_list = random.sample(range(0, dataset_size), dataset_size)\n",
    "        for idx in sample_list:\n",
    "            frame_name = data_list[idx][0]\n",
    "            data_len = data_list[idx][1]\n",
    "            target_x = []\n",
    "            target_y = []\n",
    "            target = []\n",
    "            out_x = []\n",
    "            out_y = []\n",
    "            out = []\n",
    "            net.init_hidden(net.LSTM_SIZE)\n",
    "            for frame_num in range(data_len-1):\n",
    "                file = open(ann_path + frame_name + '.txt','r')\n",
    "                file_split = file.read().splitlines()\n",
    "                next_frame = file_split[1]\n",
    "                img = Image.open(img_path + next_frame + '.jpg')\n",
    "                img = img.convert('RGB')\n",
    "                img = img_transform(img)\n",
    "                x = torch.tensor([float(file_split[4]) - float(file_split[2])], requires_grad=False)\n",
    "                y = torch.tensor([float(file_split[5]) - float(file_split[3])], requires_grad=False)\n",
    "                if USE_GPU:\n",
    "                    img = img.cuda()\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                if frame_num != 0:\n",
    "                    target_x = target_x + [x]\n",
    "                    target_y = target_y + [y]\n",
    "                output_x, output_y = net(img, x, y)\n",
    "                out_x = out_x + [output_x]\n",
    "                out_y = out_y + [output_y]\n",
    "                frame_name = next_frame\n",
    "            file = open(ann_path + frame_name + '.txt','r')\n",
    "            file_split = file.read().splitlines()\n",
    "            x = torch.tensor([float(file_split[4]) - float(file_split[2])])\n",
    "            y = torch.tensor([float(file_split[5]) - float(file_split[3])])\n",
    "            if USE_GPU:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            target_x = target_x + [x]\n",
    "            target_y = target_y + [y]\n",
    "                \n",
    "            target_x = torch.stack(target_x, 1).squeeze(1).view(-1)\n",
    "            target_y = torch.stack(target_y, 1).squeeze(1).view(-1)\n",
    "            target = torch.cat((target_x, target_y))\n",
    "            out_x = torch.stack(out_x, 1).squeeze(2).view(-1)\n",
    "            out_y = torch.stack(out_y, 1).squeeze(2).view(-1)\n",
    "            out = torch.cat((out_x, out_y)) #torch.Size([n])\n",
    "            \n",
    "            def clousure():\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(out, target)\n",
    "                print(epoch, '>>', idx, '>> loss:', loss.item())\n",
    "                loss.backward(retain_graph = True)\n",
    "                return loss\n",
    "            optimizer.step(clousure)\n",
    "            #torch.cuda.empty_cache()\n",
    "            \n",
    "    return net\n",
    "\n",
    "'''np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "net = PredictNet()\n",
    "#net.double()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.LBFGS(net.parameters(), lr=0.1)\n",
    "if USE_GPU:\n",
    "    net = net.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "net = train_model(optimizer, criterion, net, 1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 || Seq: 0 / 172 || loss: 1.6423445213586092\n",
      "Epoch:  0 || Seq: 10 / 172 || loss: 1.456771049987186\n",
      "Epoch:  0 || Seq: 20 / 172 || loss: 2.5996700927615164\n",
      "Epoch:  0 || Seq: 30 / 172 || loss: 1.8380051096280416\n",
      "Epoch:  0 || Seq: 40 / 172 || loss: 1.2943714633584023\n",
      "Epoch:  0 || Seq: 50 / 172 || loss: 1.3741947388962696\n",
      "Epoch:  0 || Seq: 60 / 172 || loss: 2.354999005794525\n",
      "Epoch:  0 || Seq: 70 / 172 || loss: 2.1578871577978136\n",
      "Epoch:  0 || Seq: 80 / 172 || loss: 1.3589330792427063\n",
      "Epoch:  0 || Seq: 90 / 172 || loss: 2.0263263771408484\n",
      "Epoch:  0 || Seq: 100 / 172 || loss: 1.5845579541474581\n",
      "Epoch:  0 || Seq: 110 / 172 || loss: 1.724712113539378\n",
      "Epoch:  0 || Seq: 120 / 172 || loss: 1.796697633046853\n",
      "Epoch:  0 || Seq: 130 / 172 || loss: 1.719301238656044\n",
      "Epoch:  0 || Seq: 140 / 172 || loss: 1.552719247010019\n",
      "Epoch:  0 || Seq: 150 / 172 || loss: 1.4787592660439641\n",
      "Epoch:  0 || Seq: 160 / 172 || loss: 1.1421808819803927\n",
      "Epoch:  0 || Seq: 170 / 172 || loss: 1.2354769224629683\n",
      "Epoch:  1 || Seq: 0 / 172 || loss: 1.9242258869832563\n",
      "Epoch:  1 || Seq: 10 / 172 || loss: 2.6267789407418323\n",
      "Epoch:  1 || Seq: 20 / 172 || loss: 3.2778818430379033\n",
      "Epoch:  1 || Seq: 30 / 172 || loss: 2.513114985297708\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "img_transform = transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                    ])\n",
    "def train_model(optimizer, criterion, net, num_epochs):\n",
    "    x = None\n",
    "    y = None\n",
    "    img = None\n",
    "    epoch_loss = 0.\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        epoch_loss = 0.\n",
    "        curr_loss = 0.0\n",
    "        dataset_size = len(data_list)\n",
    "        sample_list = random.sample(range(0, dataset_size), dataset_size)\n",
    "        if epoch != 0 and epoch % 60 == 0:\n",
    "            adjust_learning_rate(optim)\n",
    "        if epoch == 0 and epoch % 5 == 0:\n",
    "            torch.save(net.state_dict(), model_path + 'predict_' + str(epoch) + '_' + str(epoch_loss/dataset_size) + '.pth')\n",
    "        for i, idx in enumerate(sample_list):\n",
    "            frame_name = data_list[idx][0]\n",
    "            data_len = data_list[idx][1]\n",
    "            net.init_hidden(net.LSTM_SIZE)\n",
    "            total_loss = 0.\n",
    "            for frame_num in range(data_len-1):\n",
    "                file = open(ann_path + frame_name + '.txt','r')\n",
    "                file_split = file.read().splitlines()\n",
    "                next_frame = file_split[1]\n",
    "                img = Image.open(img_path + next_frame + '.jpg')\n",
    "                img = img.convert('RGB')\n",
    "                img = img_transform(img)\n",
    "                x = torch.tensor([float(file_split[4]) - float(file_split[2])], requires_grad=False)\n",
    "                y = torch.tensor([float(file_split[5]) - float(file_split[3])], requires_grad=False)\n",
    "                if USE_GPU:\n",
    "                    img = img.cuda()\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                output = net(img, x, y)\n",
    "                frame_name = next_frame\n",
    "                file = open(ann_path + frame_name + '.txt','r')\n",
    "                file_split = file.read().splitlines()\n",
    "                target_x = torch.tensor([float(file_split[4]) - float(file_split[2])])\n",
    "                target_y = torch.tensor([float(file_split[5]) - float(file_split[3])])\n",
    "                if USE_GPU:\n",
    "                    target_x = target_x.cuda()\n",
    "                    target_y = target_y.cuda()\n",
    "                target = torch.cat((target_x, target_y))\n",
    "                loss = criterion(output, target)\n",
    "                total_loss = total_loss + loss.item()\n",
    "                epoch_loss = epoch_loss + total_loss\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "            if i % 10 == 0:\n",
    "                print('Epoch: ', epoch, '|| Seq: ' + str(i) + ' / '+ str(dataset_size), '|| loss:', total_loss/(data_len-1))\n",
    "    return net\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "net = PredictNet()\n",
    "#net.double()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "if USE_GPU:\n",
    "    net = net.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "net = train_model(optimizer, criterion, net, 201)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
