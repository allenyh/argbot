{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision\n",
    "import torch.optim.lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "EPOCH = 50\n",
    "GAMMA = 0.9\n",
    "STEP_SIZE = 200\n",
    "LR = 0.001\n",
    "USE_GPU = True\n",
    "decoder = ['buoy', 'dock', 'light_buoy', 'totem']\n",
    "data_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path = '/media/arg_ws3/TOSHIBA EXT/data/trajectory/root.txt'\n",
    "img_path = '/media/arg_ws3/TOSHIBA EXT/data/trajectory/images/'\n",
    "ann_path = '/media/arg_ws3/TOSHIBA EXT/data/trajectory/annotations/'\n",
    "model_path = '../model'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "data_list_file = open(list_path,'r')\n",
    "raw_data_list = data_list_file.read().splitlines()\n",
    "data_list = []\n",
    "for data in raw_data_list:\n",
    "    data_split = data.split(',')\n",
    "    first_frame = data_split[0]\n",
    "    data_len = int(data_split[1])\n",
    "    if data_len >= 10:\n",
    "        data_list.append([first_frame, data_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Layer Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRN(nn.Module):\n",
    "    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=True):\n",
    "        super(LRN, self).__init__()\n",
    "        self.ACROSS_CHANNELS = ACROSS_CHANNELS\n",
    "        if ACROSS_CHANNELS:\n",
    "            self.average=nn.AvgPool3d(kernel_size=(local_size, 1, 1),\n",
    "                    stride=1,\n",
    "                    padding=(int((local_size-1.0)/2), 0, 0))\n",
    "        else:\n",
    "            self.average=nn.AvgPool2d(kernel_size=local_size,\n",
    "                    stride=1,\n",
    "                    padding=int((local_size-1.0)/2))\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.ACROSS_CHANNELS:\n",
    "            div = x.pow(2).unsqueeze(1)\n",
    "            div = self.average(div).squeeze(1)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        else:\n",
    "            div = x.pow(2)\n",
    "            div = self.average(div)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        x = x.div(div)\n",
    "        return x\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class alexnet_conv_layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(alexnet_conv_layers, self).__init__()\n",
    "        self.base_features = torchvision.models.alexnet(pretrained = True).features\n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(64, out_channels=16, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(192, out_channels=32, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.skip5 = nn.Sequential(\n",
    "            nn.Conv2d(256, out_channels=64, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Linear(37104 * 2, 2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Freeze those weights\n",
    "        for p in self.base_features.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def forward(self, x, y):\n",
    "        layer_extractor_x = []\n",
    "        layer_extractor_y = []\n",
    "        for idx, model in enumerate(self.base_features):\n",
    "            x = model(x)\n",
    "            y = model(y)\n",
    "            if idx in {2, 5, 11}: # layer output of conv1, conv2 , conv5(before pooling layer)\n",
    "                layer_extractor_x.append(x)\n",
    "                layer_extractor_y.append(y)\n",
    "                \n",
    "        x_out_flat = x.view(1, -1) #(1, 256, 6, 6) --> (1, 9216)\n",
    "        x_out_skip1 = self.skip1(layer_extractor_x[0]) #(1, 64, 27, 27) -> (11664)\n",
    "        x_out_skip2 = self.skip2(layer_extractor_x[1]) #(1, 192, 13, 13) -> (5408)\n",
    "        x_out_skip5 = self.skip5(layer_extractor_x[2]) #(1, 256, 13, 13) -> (10816)\n",
    "        x_out = torch.cat((x_out_skip1, x_out_skip2, x_out_skip5, x_out_flat), dim=1)\n",
    "        \n",
    "        y_out_flat = y.view(1, -1) #(1, 256, 6, 6) --> (1, 9216)\n",
    "        y_out_skip1 = self.skip1(layer_extractor_y[0]) #(1, 64, 27, 27) -> (11664)\n",
    "        y_out_skip2 = self.skip2(layer_extractor_y[1]) #(1, 192, 13, 13) -> (5408)\n",
    "        y_out_skip5 = self.skip5(layer_extractor_y[2]) #(1, 256, 13, 13) -> (10816)\n",
    "        y_out = torch.cat((y_out_skip1, y_out_skip2, y_out_skip5, y_out_flat), dim=1)\n",
    "        \n",
    "        final_out = torch.cat((x_out, y_out), dim=1)\n",
    "        conv_out = self.conv6(final_out) # (1, 2048)\n",
    "        return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51])\n",
      "torch.Size([1, 51])\n"
     ]
    }
   ],
   "source": [
    "a = Variable(torch.rand(1, 51)).cuda()\n",
    "print(a.shape)\n",
    "b = torch.zeros(1, 51).cuda()\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PredictNet,self).__init__()\n",
    "        self.LSTM_SIZE = 256\n",
    "        alexnet = torchvision.models.alexnet(pretrained = True)\n",
    "        self.feature = alexnet.features\n",
    "        classifier = list(alexnet.classifier.children())\n",
    "        self.classifier = nn.Sequential(*classifier[:-1])\n",
    "        self.lstm1_x =nn.LSTMCell(4096 + 1, self.LSTM_SIZE)\n",
    "        self.lstm2_x = nn.LSTMCell(self.LSTM_SIZE, self.LSTM_SIZE)\n",
    "        self.lstm1_y =nn.LSTMCell(4096 + 1, self.LSTM_SIZE)\n",
    "        self.lstm2_y = nn.LSTMCell(self.LSTM_SIZE, self.LSTM_SIZE)\n",
    "        self.linear_x = nn.Linear(self.LSTM_SIZE, 1)\n",
    "        self.linear_y = nn.Linear(self.LSTM_SIZE, 1)\n",
    "        \n",
    "        self.h_x1 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.h_y1 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.h_x2 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.h_y2 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.c_x1 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.c_y1 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.c_x2 = self.get_hidden(self.LSTM_SIZE)\n",
    "        self.c_y2 = self.get_hidden(self.LSTM_SIZE)\n",
    "\n",
    "    def init_hidden(self, num):\n",
    "        self.h_x1 = self.h_x1.detach()\n",
    "        self.h_y1 = self.h_y1.detach()\n",
    "        self.h_x2 = self.h_x2.detach()\n",
    "        self.h_y2 = self.h_y2.detach()\n",
    "        self.c_x1 = self.c_x1.detach()\n",
    "        self.c_y1 = self.c_y1.detach()\n",
    "        self.c_x2 = self.c_x2.detach()\n",
    "        self.c_y2 = self.c_y2.detach()\n",
    "        \n",
    "        self.h_x1 = self.get_hidden(num)\n",
    "        self.h_y1 = self.get_hidden(num)\n",
    "        self.h_x2 = self.get_hidden(num)\n",
    "        self.h_y2 = self.get_hidden(num)\n",
    "        self.c_x1 = self.get_hidden(num)\n",
    "        self.c_y1 = self.get_hidden(num)\n",
    "        self.c_x2 = self.get_hidden(num)\n",
    "        self.c_y2 = self.get_hidden(num)\n",
    "\n",
    "    def get_hidden(self, num):\n",
    "        if USE_GPU:\n",
    "            #return (Variable(torch.rand(1, num)).cuda(), Variable(torch.rand(1, num)).cuda())\n",
    "            return Variable(torch.rand(1, num)).cuda()\n",
    "            #return torch.zeros(1, num).cuda()\n",
    "        else:\n",
    "            #return (Variable(torch.rand(1, num)), Variable(torch.rand(1, num)))\n",
    "            return Variable(torch.rand(1, num))\n",
    "            #return torch.zeros(t1, num)\n",
    "        \n",
    "    def forward(self, img, input_x, input_y):\n",
    "        '''h_x1 = torch.zeros(input.size(0), self.LSTM_SIZE, dtype=torch.double)\n",
    "        h_y1 = torch.zeros(input.size(0), self.LSTM_SIZE, dtype=torch.double)\n",
    "        h_x2 = torch.zeros(input.size(0), self.LSTM_SIZE, dtype=torch.double)\n",
    "        h_y2 = torch.zeros(input.size(0), self.LSTM_SIZE, dtype=torch.double)\n",
    "        c_x1 = torch.zeros(input.size(0), self.LSTM_SIZE, dtype=torch.double)\n",
    "        c_y1 = torch.zeros(input.size(0), self.LSTM_SIZE, dtype=torch.double)\n",
    "        c_x2 = torch.zeros(input.size(0), self.LSTM_SIZE, dtype=torch.double)\n",
    "        c_y2 = torch.zeros(input.size(0), self.LSTM_SIZE, dtype=torch.double)'''\n",
    "        \n",
    "        img_features = self.feature(img.unsqueeze(0))\n",
    "        img_features = img_features.view(img_features.size(0), -1)\n",
    "        img_features = self.classifier(img_features).view(-1)\n",
    "        x = input_x\n",
    "        y = input_y\n",
    "        \n",
    "        cat_x = torch.cat((img_features, x), dim=0).view(1, -1)\n",
    "        self.h_x1, self.c_x1 = self.lstm1_x(cat_x, (self.h_x1, self.c_x1))\n",
    "        self.h_x2, self.c_x2 = self.lstm2_y(self.h_x1, (self.h_x2, self.c_x2))\n",
    "        output_x = self.linear_x(self.h_x2)\n",
    "        \n",
    "        cat_y = torch.cat((img_features, y), dim=0).view(1, -1)\n",
    "        self.h_y1, self.c_y1 = self.lstm1_y(cat_y, (self.h_y1, self.c_y1))\n",
    "        self.h_y2, self.c_y2 = self.lstm2_y(self.h_y1, (self.h_y2, self.c_y2))\n",
    "        output_y = self.linear_y(self.h_y2)\n",
    "        \n",
    "        return output_x, output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "loss: 2.383277654647827\n",
      "loss: 2.383277654647827\n",
      "60\n",
      "loss: 2.0790534019470215\n",
      "loss: 2.0790534019470215\n",
      "41\n",
      "loss: 1.5399657487869263\n",
      "loss: 1.5399657487869263\n",
      "106\n",
      "loss: 3.0443363189697266\n",
      "loss: 3.0443363189697266\n",
      "154\n",
      "loss: 1.6094096899032593\n",
      "loss: 1.6094096899032593\n",
      "23\n",
      "loss: 1.543656587600708\n",
      "loss: 1.543656587600708\n",
      "75\n",
      "loss: 1.1274205446243286\n",
      "loss: 1.1274205446243286\n",
      "111\n",
      "loss: 1.3210667371749878\n",
      "loss: 1.3210667371749878\n",
      "96\n",
      "loss: 2.489140033721924\n",
      "loss: 2.489140033721924\n",
      "58\n",
      "loss: 1.3314810991287231\n",
      "loss: 1.3314810991287231\n",
      "85\n",
      "loss: 0.8806560635566711\n",
      "loss: 0.8806560635566711\n",
      "24\n",
      "loss: 2.145580530166626\n",
      "loss: 2.145580530166626\n",
      "43\n",
      "loss: 1.0515984296798706\n",
      "loss: 1.0515984296798706\n",
      "167\n",
      "loss: 0.9372762441635132\n",
      "loss: 0.9372762441635132\n",
      "170\n",
      "loss: 2.144508123397827\n",
      "loss: 2.144508123397827\n",
      "149\n",
      "loss: 2.5602657794952393\n",
      "loss: 2.5602657794952393\n",
      "147\n",
      "loss: 4.489132881164551\n",
      "loss: 4.489132881164551\n",
      "108\n",
      "loss: 0.7426080107688904\n",
      "loss: 0.7426080107688904\n",
      "49\n",
      "loss: 1.4295904636383057\n",
      "loss: 1.4295904636383057\n",
      "145\n",
      "loss: 1.7674434185028076\n",
      "loss: 1.7674434185028076\n",
      "103\n",
      "loss: 1.298443078994751\n",
      "loss: 1.298443078994751\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 11.91 GiB total capacity; 10.69 GiB already allocated; 39.75 MiB free; 194.98 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4b64012578e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-4b64012578e4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(optimizer, criterion, net, num_epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclousure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     \u001b[0;31m# the reason we do this: in a stochastic setting,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;31m# no use to re-evaluate that function here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                     \u001b[0mflat_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mabs_grad_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4b64012578e4>\u001b[0m in \u001b[0;36mclousure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclousure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 11.91 GiB total capacity; 10.69 GiB already allocated; 39.75 MiB free; 194.98 MiB cached)"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "img_transform = transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                    ])\n",
    "def train_model(optimizer, criterion, net, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch != 0 and epoch % 5 == 0:\n",
    "            adjust_learning_rate(optim)\n",
    "        curr_loss = 0.0\n",
    "        dataset_size = len(data_list)\n",
    "        sample_list = random.sample(range(0, dataset_size), dataset_size)\n",
    "        for idx in sample_list:\n",
    "            print(idx)\n",
    "            frame_name = data_list[idx][0]\n",
    "            data_len = data_list[idx][1]\n",
    "            target_x = []\n",
    "            target_y = []\n",
    "            target = []\n",
    "            out_x = []\n",
    "            out_y = []\n",
    "            out = []\n",
    "            net.init_hidden(net.LSTM_SIZE)\n",
    "            for frame_num in range(data_len-1):\n",
    "                file = open(ann_path + frame_name + '.txt','r')\n",
    "                file_split = file.read().splitlines()\n",
    "                next_frame = file_split[1]\n",
    "                img = Image.open(img_path + next_frame + '.jpg')\n",
    "                img = img.convert('RGB')\n",
    "                img = img_transform(img)\n",
    "                x = torch.tensor([float(file_split[4]) - float(file_split[2])])\n",
    "                y = torch.tensor([float(file_split[5]) - float(file_split[3])])\n",
    "                if USE_GPU:\n",
    "                    img = img.cuda()\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                if frame_num != 0:\n",
    "                    target_x = target_x + [x]\n",
    "                    target_y = target_y + [y]\n",
    "                output_x, output_y = net(img, x, y)\n",
    "                out_x = out_x + [output_x]\n",
    "                out_y = out_y + [output_y]\n",
    "                frame_name = next_frame\n",
    "            file = open(ann_path + frame_name + '.txt','r')\n",
    "            file_split = file.read().splitlines()\n",
    "            x = torch.tensor([float(file_split[4]) - float(file_split[2])])\n",
    "            y = torch.tensor([float(file_split[5]) - float(file_split[3])])\n",
    "            if USE_GPU:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            target_x = target_x + [x]\n",
    "            target_y = target_y + [y]\n",
    "                \n",
    "            target_x = torch.stack(target_x, 1).squeeze(1).view(-1)\n",
    "            target_y = torch.stack(target_y, 1).squeeze(1).view(-1)\n",
    "            target = torch.cat((target_x, target_y))\n",
    "            out_x = torch.stack(out_x, 1).squeeze(2).view(-1)\n",
    "            out_y = torch.stack(out_y, 1).squeeze(2).view(-1)\n",
    "            out = torch.cat((out_x, out_y)) #torch.Size([n])\n",
    "            \n",
    "            def clousure():\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(out, target)\n",
    "                print('loss:', loss.item())\n",
    "                loss.backward(retain_graph = True)\n",
    "                return loss\n",
    "            optimizer.step(clousure)\n",
    "            \n",
    "    return net\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "net = PredictNet()\n",
    "#net.double()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.LBFGS(net.parameters(), lr=0.1)\n",
    "if USE_GPU:\n",
    "    net = net.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "net = train_model(optimizer, criterion, net, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
