{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision\n",
    "import torch.optim.lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "EPOCH = 50\n",
    "GAMMA = 0.9\n",
    "STEP_SIZE = 200\n",
    "LR = 0.001\n",
    "USE_GPU = True\n",
    "decoder = ['buoy', 'dock', 'light_buoy', 'totem']\n",
    "data_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "img_path = '/home/arg_ws3/david_trainings/image_data'\n",
    "model_path = './model'\n",
    "pretrain_PATH = \"./alexnet-owt-4df8aa71.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = torchvision.models.alexnet(pretrained = False)\n",
    "net.load_state_dict(torch.load(pretrain_PATH))\n",
    "net.classifier[6] = nn.Linear(4096, 4)\n",
    "if USE_GPU:\n",
    "    net = net.cuda()\n",
    "#optimizer = torch.optim.Adam(alexnet.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = LR, momentum=0.9)\n",
    "loss_func = nn.CrossEntropyLoss() # the target label is not one-hotted\n",
    "if USE_GPU:\n",
    "    loss_func = loss_func.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "class alexnet_conv_layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(alexnet_conv_layers, self).__init__()\n",
    "        input_channels = 3\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, out_channels=96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(96, out_channels=16, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, groups=2, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(256, out_channels=32, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1, groups=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1, groups=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool5 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv5_flat = nn.Sequential(\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.skip5 = nn.Sequential(\n",
    "            nn.Conv2d(256, out_channels=64, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Linear(37104 * 2, 2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_out1 = self.conv1(x)\n",
    "        x_out_skip1 = self.skip1(x_out1)\n",
    "\n",
    "        x_out2 = self.conv2(x_out1)\n",
    "        x_out_skip2 = self.skip2(x_out2)\n",
    "\n",
    "        x_out3 = self.conv3(x_out2)\n",
    "        x_out4 = self.conv4(x_out3)\n",
    "        x_out5 = self.conv5(x_out4)\n",
    "\n",
    "        x_out_skip5 = self.skip5(x_out5)\n",
    "\n",
    "        x_out_pool =self.pool5(x_out5)\n",
    "        x_out_pool = self.conv5_flat( x_out_pool)\n",
    "        x_out = torch.cat((x_out_skip1, x_out_skip2, x_out_skip5, x_out_pool), dim=1)\n",
    "\n",
    "        y_out1 = self.conv1(y)\n",
    "        y_out_skip1 = self.skip1(y_out1)\n",
    "\n",
    "        y_out2 = self.conv2(y_out1)\n",
    "        y_out_skip2 = self.skip2(y_out2)\n",
    "\n",
    "        y_out3 = self.conv3(y_out2)\n",
    "        y_out4 = self.conv4(y_out3)\n",
    "        y_out5 = self.conv5(y_out4)\n",
    "\n",
    "        y_out_skip5 = self.skip5(y_out5)\n",
    "\n",
    "        y_out_pool =self.pool5(y_out5)\n",
    "        y_out_pool = self.conv5_flat(y_out_pool)\n",
    "        y_out = torch.cat((y_out_skip1, y_out_skip2, y_out_skip5, y_out_pool), dim=1)\n",
    "\n",
    "        final_out = torch.cat((x_out, y_out), dim=1)\n",
    "        conv_out = self.conv6(final_out)\n",
    "        return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class alexnet_conv_layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(alexnet_conv_layers, self).__init__()\n",
    "        self.base_features = torchvision.models.alexnet(pretrained = True).features\n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(64, out_channels=16, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(192, out_channels=32, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.skip5 = nn.Sequential(\n",
    "            nn.Conv2d(256, out_channels=64, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Linear(37104 * 2, 2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        '''\n",
    "        # Freeze those weights\n",
    "        for p in self.features.parameters():\n",
    "            p.requires_grad = False\n",
    "        '''\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        layer_extractor_x = []\n",
    "        layer_extractor_y = []\n",
    "        for idx, model in enumerate(self.base_features):\n",
    "            x = model(x)\n",
    "            y = model(y)\n",
    "            if idx in {2, 5, 11}: # layer output of conv1, conv2 , conv5(before pooling layer)\n",
    "                layer_extractor_x.append(x)\n",
    "                layer_extractor_y.append(y)\n",
    "                \n",
    "        x_out_flat = x.view(1, -1) #(1, 256, 6, 6) --> (1, 9216)\n",
    "        x_out_skip1 = self.skip1(layer_extractor_x[0]) #(1, 64, 27, 27) -> (11664)\n",
    "        x_out_skip2 = self.skip2(layer_extractor_x[1]) #(1, 192, 13, 13) -> (5408)\n",
    "        x_out_skip5 = self.skip5(layer_extractor_x[2]) #(1, 256, 13, 13) -> (10816)\n",
    "        x_out = torch.cat((x_out_skip1, x_out_skip2, x_out_skip5, x_out_flat), dim=1)\n",
    "        \n",
    "        y_out_flat = y.view(1, -1) #(1, 256, 6, 6) --> (1, 9216)\n",
    "        y_out_skip1 = self.skip1(layer_extractor_y[0]) #(1, 64, 27, 27) -> (11664)\n",
    "        y_out_skip2 = self.skip2(layer_extractor_y[1]) #(1, 192, 13, 13) -> (5408)\n",
    "        y_out_skip5 = self.skip5(layer_extractor_y[2]) #(1, 256, 13, 13) -> (10816)\n",
    "        y_out = torch.cat((y_out_skip1, y_out_skip2, y_out_skip5, y_out_flat), dim=1)\n",
    "        \n",
    "        final_out = torch.cat((x_out, y_out), dim=1)\n",
    "        conv_out = self.conv6(final_out) # (1, 2048)\n",
    "        return conv_out\n",
    "fake_data = torch.empty(1, 3, 227, 227)\n",
    "base_model = torchvision.models.alexnet(pretrained = True)\n",
    "net = alexnet_conv_layers()\n",
    "out = net(fake_data, fake_data)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alexnet_conv_layers(\n",
       "  (base_features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2c537a1152e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net1' is not defined"
     ]
    }
   ],
   "source": [
    "n1 = list(net1.parameters())\n",
    "print(len(n1[1]))\n",
    "a = list(net.features.parameters())\n",
    "print(len(a[2]))\n",
    "b = torch.tensor(a[2])\n",
    "print(b.shape)\n",
    "b = b.view(1, -1)\n",
    "print(b.shape)\n",
    "#print(net.features[0].parameters())\n",
    "#for p in net.features.parameters():\n",
    "#    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiViewNet(\n",
      "  (base_features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (base_classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (new_classifier): Sequential(\n",
      "    (0): Linear(in_features=4099, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MultiViewNet(nn.Module):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        super(MultiViewNet, self).__init__()\n",
    "        # Everything except the last linear layer\n",
    "        self.base_features = base_model.features\n",
    "        self.base_classifier = nn.Sequential(*base_model.classifier[:-1])\n",
    "        self.new_classifier = nn.Sequential(\n",
    "            nn.Linear(4099, num_classes)\n",
    "        )\n",
    "        self.modelName = 'MultiViewNet'\n",
    "        \n",
    "        '''\n",
    "        # Freeze those weights\n",
    "        for p in self.features.parameters():\n",
    "            p.requires_grad = False\n",
    "        '''\n",
    "\n",
    "    def forward(self, img, scale):\n",
    "        f = self.base_features(img)\n",
    "        f = f.view(f.size(0), -1)\n",
    "        fc2 = self.base_classifier(f)\n",
    "        fc2_cat = torch.cat((scale[0], scale[1], scale[2], fc2), dim=1)\n",
    "        y = self.new_classifier(fc2_cat)\n",
    "        return y\n",
    "\n",
    "base_model = torchvision.models.alexnet(pretrained = False)\n",
    "multiviewnet = MultiViewNet(base_model, 4)\n",
    "if USE_GPU:\n",
    "    multiviewnet = multiviewnet.cuda()\n",
    "#for p in multiviewnet.base_features[0].parameters():\n",
    "#    print(p.name, p.data)\n",
    "#optimizer = torch.optim.Adam(alexnet.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "optimizer = torch.optim.SGD(multiviewnet.parameters(), lr = LR, momentum=0.9)\n",
    "loss_func = nn.CrossEntropyLoss() # the target label is not one-hotted\n",
    "if USE_GPU:\n",
    "    loss_func = loss_func.cuda()\n",
    "print(multiviewnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
